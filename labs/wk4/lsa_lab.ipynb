{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\CKhan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['talk.politics.mideast']\n",
    "dataset = fetch_20newsgroups(subset='all', shuffle=True, random_state=42, categories=categories)\n",
    "corpus = dataset.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopset = set(stopwords.words('english'))\n",
    "stopset.update(['From:', 'Subject:', 'Re:', 'Lines:', 'In-reply-to:', 'Organization:', 'NNTP-Posting-Host:', '\\n', 'GMT', 'writes:', 'wrote:'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From: amoss@shuldig.cs.huji.ac.il (Amos Shapira)\\nSubject: Re: Final Solution in Palestine ?\\nOrganization: Inst. of Comp. Sci., Hebrew University, Jerusalem, Israel\\nLines: 30\\nNNTP-Posting-Host: shuldig.cs.huji.ac.il\\nIn-reply-to: ahmeda@McRCIM.McGill.EDU\\'s message of Sun, 25 Apr 93 17:10:03 GMT\\n\\nahmeda@McRCIM.McGill.EDU (Ahmed Abu-Abed) writes:\\n\\n|What Hamas and Islamic Jihad believe in, as far as I can get from the Arab\\n|media,\\n|is an Islamic state that protects the rights of all its inhabitants under\\n|Koranic\\n|Law. This would be a reversal of the 1948 situation in which the Jews in\\n|Palestine took control of the land and its (mostly Muslim) inhabitants.\\n\\nThe borders of the Jewish state as drawn by the U.N. included the areas which\\ncontained mostly Jews,  that\\'s what the surveys and the numerous commitees\\nwhere after when they visited here.\\n\\n|However, whoever committed crimes against humanity (torture, blowing up their\\n|homes, murders,...) must be treated and tried as a war criminal. The political\\n|thought of these movements shows that a freedom of choice will be given to the\\n|Jews in living under the new law or leaving to the destintion of their choice.\\n\\nI never touched an Arab during my army service and never voted for anyone more\\nright than the Green party.  Will I be spared by these \"humanist standards\"?\\n(or will anyone stop to consider this before sloughtering me?)\\n\\nI doubt it.  And not only because of the past record of murdering helpless\\nwomen and children since the turn of the century up to these days.\\n\\n--\\n--Amos Shapira (Jumper Extraordinaire) |  \"It is true that power corrupts,\\nC.S. System Group, Hebrew University,  |   but absolute power is better!\"\\nJerusalem 91904, ISRAEL                |\\namoss@cs.huji.ac.il                    |          -- the Demon to his son\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example document before vectorizing\n",
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words=stopset, use_idf=True, ngram_range=(1,3),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Populate maxtrix\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x327287 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 464 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformed document after TF-IDF\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 144231)\t0.0425783728261\n",
      "  (0, 14472)\t0.0425783728261\n",
      "  (0, 24471)\t0.0425783728261\n",
      "  (0, 152971)\t0.0425783728261\n",
      "  (0, 12799)\t0.0425783728261\n",
      "  (0, 156576)\t0.0425783728261\n",
      "  (0, 47915)\t0.0425783728261\n",
      "  (0, 227083)\t0.0425783728261\n",
      "  (0, 14223)\t0.0425783728261\n",
      "  (0, 304075)\t0.0425783728261\n",
      "  (0, 136286)\t0.0425783728261\n",
      "  (0, 130535)\t0.0425783728261\n",
      "  (0, 283726)\t0.0425783728261\n",
      "  (0, 75567)\t0.0425783728261\n",
      "  (0, 227101)\t0.0425783728261\n",
      "  (0, 298053)\t0.0425783728261\n",
      "  (0, 108032)\t0.0425783728261\n",
      "  (0, 159911)\t0.0425783728261\n",
      "  (0, 262917)\t0.0417088438074\n",
      "  (0, 24461)\t0.0417088438074\n",
      "  (0, 82501)\t0.0528126410187\n",
      "  (0, 60902)\t0.0528126410187\n",
      "  (0, 300869)\t0.0528126410187\n",
      "  (0, 266558)\t0.0528126410187\n",
      "  (0, 63008)\t0.0528126410187\n",
      "  :\t:\n",
      "  (0, 140614)\t0.0144758240949\n",
      "  (0, 226598)\t0.0136611835371\n",
      "  (0, 202168)\t0.0145790770225\n",
      "  (0, 9416)\t0.0245478338003\n",
      "  (0, 174416)\t0.00742968672947\n",
      "  (0, 152874)\t0.0281145455242\n",
      "  (0, 156568)\t0.0511592426124\n",
      "  (0, 304060)\t0.0263281984064\n",
      "  (0, 136246)\t0.0651569765106\n",
      "  (0, 256441)\t0.0384470294266\n",
      "  (0, 70184)\t0.0384470294266\n",
      "  (0, 148543)\t0.0425783728261\n",
      "  (0, 210651)\t0.0085624366582\n",
      "  (0, 213481)\t0.0489360452029\n",
      "  (0, 269604)\t0.0269997998753\n",
      "  (0, 113318)\t0.0264606944461\n",
      "  (0, 279574)\t0.00738246398433\n",
      "  (0, 262913)\t0.077988257724\n",
      "  (0, 24454)\t0.077988257724\n",
      "  (0, 144211)\t0.0899793942984\n",
      "  (0, 14454)\t0.0938169110238\n",
      "  (0, 141811)\t0.100795134461\n",
      "  (0, 79671)\t0.0578157927553\n",
      "  (0, 264855)\t0.077988257724\n",
      "  (0, 24465)\t0.077988257724\n"
     ]
    }
   ],
   "source": [
    "# Display term index and associated TF-IDF score\n",
    "# Only terms with a TF-IDF score > 0 are stored\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Semantic Analysis\n",
    "Matrix Decomponsition:\n",
    "\n",
    "$$X \\approx USV^{T}$$\n",
    "\n",
    "**X**: m x n matrix, where m = # documents, n = # terms, k = # concepts\n",
    "\n",
    "**U**: m x k matrix, where row (m) = documents and col (k) = concepts\n",
    "\n",
    "**S**: k x k diagonal matix, which shows amt of variation captured from each concept\n",
    "\n",
    "**V**: n x k matrix, where row (n) = terms and col (k) = concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(940, 327287)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of documents by number of terms\n",
    "# Term count includes bigrams and trigrams in addition to singular terms\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Instantiate an instance of TruncatedSVD\n",
    "# TruncatedSVD is engine used to perform matrix decomposition\n",
    "lsa = TruncatedSVD(n_components=20, n_iter=100, random_state=333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=20, n_iter=100,\n",
       "       random_state=333, tol=0.0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decompose maxtrix X into matrices U, S, and V\n",
    "lsa.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00742081,  0.00014406,  0.00014406, ...,  0.00106203,\n",
       "        0.00106203,  0.00106203])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First row of V\n",
    "# V(row) = term, V(col) = concept\n",
    "# Each value represents the importance of the term to the concept\n",
    "lsa.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept 0:\n",
      "edu\n",
      "armenian\n",
      "israel\n",
      "armenians\n",
      "turkish\n",
      "people\n",
      "jews\n",
      "israeli\n",
      "jake\n",
      "one\n",
      " \n",
      "Concept 1:\n",
      "armenian\n",
      "turkey\n",
      "istanbul\n",
      "serdar argic\n",
      "turkish\n",
      "00 150 00\n",
      "armenia\n",
      "00 1993 center\n",
      "serdar\n",
      "turks\n",
      " \n",
      "Concept 2:\n",
      "istanbul\n",
      "ankara\n",
      "professor\n",
      "osmanli\n",
      "professor history\n",
      "edu\n",
      "ermeni\n",
      "foreign office\n",
      "subject\n",
      "ed\n",
      " \n",
      "Concept 3:\n",
      "com\n",
      "jake\n",
      "turkish\n",
      "russian\n",
      "ottoman\n",
      "turkey\n",
      "000\n",
      "armenia\n",
      "population\n",
      "villages\n",
      " \n",
      "Concept 4:\n",
      "armenian\n",
      "russian\n",
      "israel\n",
      "would\n",
      "00 1993\n",
      "jews\n",
      "arabs\n",
      "posting\n",
      "armenians\n",
      "know\n",
      " \n",
      "Concept 5:\n",
      "like\n",
      "jake\n",
      "00 1993 aryans\n",
      "israeli\n",
      "armenian\n",
      "could\n",
      "government\n",
      "organization\n",
      "dead\n",
      "paragraph\n",
      " \n",
      "Concept 6:\n",
      "people\n",
      "writes\n",
      "would\n",
      "world\n",
      "serdar argic\n",
      "subject\n",
      "argic\n",
      "dro\n",
      "even\n",
      "djul\n",
      " \n",
      "Concept 7:\n",
      "israel\n",
      "00 150 00\n",
      "people\n",
      "00 150\n",
      "world\n",
      "00 1993\n",
      "soviet\n",
      "article\n",
      "professor\n",
      "organization\n",
      " \n",
      "Concept 8:\n",
      "know\n",
      "university\n",
      "people\n",
      "armenian\n",
      "way\n",
      "genocide\n",
      "cs\n",
      "professor\n",
      "00 00 1993\n",
      "would\n",
      " \n",
      "Concept 9:\n",
      "lines\n",
      "would\n",
      "armenia\n",
      "like\n",
      "center\n",
      "since\n",
      "tartar\n",
      "com\n",
      "muslim\n",
      "tartars\n",
      " \n",
      "Concept 10:\n",
      "serdar argic\n",
      "turkish\n",
      "00 150\n",
      "could\n",
      "research\n",
      "new\n",
      "adam\n",
      "world\n",
      "ca\n",
      "get\n",
      " \n",
      "Concept 11:\n",
      "turkish\n",
      "arab\n",
      "rights\n",
      "argic\n",
      "turks\n",
      "000\n",
      "com\n",
      "law\n",
      "department\n",
      "armenia\n",
      " \n",
      "Concept 12:\n",
      "jews\n",
      "get\n",
      "right\n",
      "rights\n",
      "armenians\n",
      "00 150 00\n",
      "armenia\n",
      "turks\n",
      "many\n",
      "article\n",
      " \n",
      "Concept 13:\n",
      "writes\n",
      "israel\n",
      "would\n",
      "israeli\n",
      "serdar argic\n",
      "going\n",
      "many\n",
      "say\n",
      "rights\n",
      "arab\n",
      " \n",
      "Concept 14:\n",
      "one\n",
      "organization\n",
      "jews\n",
      "genocide\n",
      "armenia\n",
      "clock\n",
      "two\n",
      "00 00 1993\n",
      "uucp\n",
      "soviet armenia\n",
      " \n",
      "Concept 15:\n",
      "article\n",
      "israel\n",
      "many\n",
      "turkish\n",
      "jews\n",
      "would\n",
      "muslim\n",
      "zuma uucp\n",
      "uci\n",
      "know\n",
      " \n",
      "Concept 16:\n",
      "edu\n",
      "israel\n",
      "serdar\n",
      "lines\n",
      "serdar argic\n",
      "organization\n",
      "war\n",
      "00 00 1993\n",
      "ca\n",
      "university\n",
      " \n",
      "Concept 17:\n",
      "writes\n",
      "israel\n",
      "article\n",
      "00 1993 center\n",
      "subject\n",
      "armenian\n",
      "argic\n",
      "000\n",
      "organization\n",
      "turkish\n",
      " \n",
      "Concept 18:\n",
      "people\n",
      "said\n",
      "muslim\n",
      "article\n",
      "world\n",
      "edu\n",
      "first\n",
      "00 1993 center\n",
      "distribution world\n",
      "writes\n",
      " \n",
      "Concept 19:\n",
      "subject\n",
      "university\n",
      "00 1993 aryans\n",
      "00 150 00\n",
      "well\n",
      "department\n",
      "right\n",
      "news\n",
      "armenian\n",
      "organization\n",
      " \n"
     ]
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names()\n",
    "for i, comp in enumerate(lsa.components_): \n",
    "    termsInComp = zip (terms,comp)\n",
    "    sortedTerms =  sorted(termsInComp, key=lambda x: x[1], reverse=True) [:10]\n",
    "    print(\"Concept %d:\" % i )\n",
    "    for term in sortedTerms:\n",
    "        print(term[0])\n",
    "    print (\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
