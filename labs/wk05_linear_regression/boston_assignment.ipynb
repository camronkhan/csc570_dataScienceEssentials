{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston House Prices dataset\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bean = datasets.load_boston()\n",
    "print(bean.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_boston():\n",
    "    scaler = StandardScaler()\n",
    "    boston = datasets.load_boston()\n",
    "    X=boston.data\n",
    "    y=boston.target\n",
    "    X = scaler.fit_transform(X)\n",
    "    return train_test_split(X,y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(379, 13)"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a Linear Regression\n",
    "\n",
    "It's as easy as instantiating a new regression object (line 1) and giving your regression object your training data\n",
    "(line 2) by calling .fit(independent variables, dependent variable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_LR = LinearRegression()\n",
    "clf_LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a Prediction\n",
    "X_test is our holdout set of data.  We know the answer (y_test) but the computer does not.   \n",
    "\n",
    "Using the command below, I create a tuple for each observation, where I'm combining the real value (y_test) with\n",
    "the value our regressor predicts (clf.predict(X_test))\n",
    "\n",
    "Use a similiar format to get your r2 and mse metrics working.  Using the [scikit learn api](http://scikit-learn.org/stable/modules/model_evaluation.html) if you need help!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_LR = list(zip (y_test, clf_LR.predict(X_test)))\n",
    "y_pred_LR = [x[1] for x in output_LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.746871434181\n"
     ]
    }
   ],
   "source": [
    "R2_LR = r2_score(y_test, y_pred_LR)\n",
    "print(R2_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.81279917919\n"
     ]
    }
   ],
   "source": [
    "RMSE_LR = np.sqrt(mean_squared_error(y_test, y_pred_LR))\n",
    "print(RMSE_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing a New Model with L2 Regularization: sklearn.linear_model.Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_Ridge = Ridge(alpha=1)\n",
    "clf_Ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_Ridge = list(zip (y_test, clf_Ridge.predict(X_test)))\n",
    "y_pred_Ridge = [x[1] for x in output_Ridge]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.747812990757\n"
     ]
    }
   ],
   "source": [
    "R2_Ridge = r2_score(y_test, y_pred_Ridge)\n",
    "print(R2_Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.80383981005\n"
     ]
    }
   ],
   "source": [
    "RMSE_Ridge = np.sqrt(mean_squared_error(y_test, y_pred_Ridge))\n",
    "print(RMSE_Ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing a New Model with L1 Regularization: sklearn.linear_model.Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_Lasso = Lasso(alpha=1)\n",
    "clf_Lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_Lasso = list(zip (y_test, clf_Lasso.predict(X_test)))\n",
    "y_pred_Lasso = [x[1] for x in output_Lasso]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.714470790016\n"
     ]
    }
   ],
   "source": [
    "R2_Lasso = r2_score(y_test, y_pred_Lasso)\n",
    "print(R2_Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.11154787896\n"
     ]
    }
   ],
   "source": [
    "RMSE_Lasso = np.sqrt(mean_squared_error(y_test, y_pred_Lasso))\n",
    "print(RMSE_Lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging R2 and RMSE over 100 random samples and multiple alpha values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            R2_LR  R2_Ridge  R2_Lasso   RMSE_LR  RMSE_Ridge  RMSE_Lasso\n",
      "alpha                                                                  \n",
      "0.01     0.718871  0.718874  0.719197  4.819348    4.819322    4.816543\n",
      "0.10     0.718871  0.718901  0.714853  4.819348    4.819096    4.853237\n",
      "1.00     0.718871  0.719138  0.652303  4.819348    4.817081    5.372725\n",
      "10.00    0.718871  0.719703 -0.013045  4.819348    4.812537    9.182803\n",
      "100.00   0.718871  0.699378 -0.013045  4.819348    4.990290    9.182803\n",
      "1000.00  0.718871  0.506703 -0.013045  4.819348    6.414147    9.182803\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "# Take 100 random samples\n",
    "for i in range(0, 100):\n",
    "    \n",
    "    # Load data\n",
    "    X_train, X_test, y_train, y_test = load_boston()\n",
    "    \n",
    "    # Linear Regression\n",
    "    clf_LR = LinearRegression()\n",
    "    clf_LR.fit(X_train, y_train)\n",
    "    output_LR = list(zip (y_test, clf_LR.predict(X_test)))\n",
    "    y_pred_LR = [x[1] for x in output_LR]\n",
    "    R2_LR = r2_score(y_test, y_pred_LR)\n",
    "    RMSE_LR = np.sqrt(mean_squared_error(y_test, y_pred_LR))\n",
    "    \n",
    "    # Increase alpha by factors of 10 for Ridge and Lasso Regression\n",
    "    for j in range(0, 6):\n",
    "        \n",
    "        # Set alpha value\n",
    "        alpha = 0.01 * 10**j\n",
    "        \n",
    "        # Ridge Regression\n",
    "        clf_Ridge = Ridge(alpha=alpha)\n",
    "        clf_Ridge.fit(X_train, y_train)\n",
    "        output_Ridge = list(zip (y_test, clf_Ridge.predict(X_test)))\n",
    "        y_pred_Ridge = [x[1] for x in output_Ridge]\n",
    "        R2_Ridge = r2_score(y_test, y_pred_Ridge)\n",
    "        RMSE_Ridge = np.sqrt(mean_squared_error(y_test, y_pred_Ridge))\n",
    "        \n",
    "        # Lasso Regression\n",
    "        clf_Lasso = Lasso(alpha=alpha)\n",
    "        clf_Lasso.fit(X_train, y_train)\n",
    "        output_Lasso = list(zip (y_test, clf_Lasso.predict(X_test)))\n",
    "        y_pred_Lasso = [x[1] for x in output_Lasso]\n",
    "        R2_Lasso = r2_score(y_test, y_pred_Lasso)\n",
    "        RMSE_Lasso = np.sqrt(mean_squared_error(y_test, y_pred_Lasso))\n",
    "        \n",
    "        # Save data\n",
    "        data.append((alpha, R2_LR, R2_Ridge, R2_Lasso, RMSE_LR, RMSE_Ridge, RMSE_Lasso))\n",
    "\n",
    "# Create dataframe\n",
    "dataFrame = pd.DataFrame(data, columns=['alpha', 'R2_LR', 'R2_Ridge', 'R2_Lasso', 'RMSE_LR', 'RMSE_Ridge', 'RMSE_Lasso'])\n",
    "\n",
    "# Group means by alpha level\n",
    "print(dataFrame.groupby('alpha').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "**Ridge Regression:** Regarding R2 performance, Ridge Regression only slightly outperformed Linear Regression on average where alpha <= 10.  There was a significant decrease in Ridge Regression R2 performance where alpha was >= 100.  Regarding RMSE performance, Ridge Regression slightly outperformed Linear Regression where alpha < 1.  Again, there was a sharp decline in performance where alpha was >= 100.\n",
    "\n",
    "**Lasso Regression:** Regarding R2 performance, Lasso Regression slightly outperformed Linear Regression where alpha == 0.01.  Regarding RMSE performance, Lasso again only slightly outperformed Linear Regression where alpha == 0.01."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
