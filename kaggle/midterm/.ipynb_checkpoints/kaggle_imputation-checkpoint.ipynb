{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Retention Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import Imputer\n",
    "from scipy.stats import mode\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.options.display.max_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA = pd.read_csv(\"../../../kaggle_data/customer_retention/midterm_train.csv\")\n",
    "TEST_DATA = pd.read_csv(\"../../../kaggle_data/customer_retention/midterm_test.csv\")\n",
    "X = TRAIN_DATA\n",
    "X_combined = pd.concat([X, TEST_DATA])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 51)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_combined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Month Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cleanMonth(x):\n",
    "    if isinstance(x, str):\n",
    "        if x == 'Jun': return 'june'\n",
    "        elif x == 'July': return 'july'\n",
    "        elif x == 'Aug': return 'august'\n",
    "        elif x == 'May': return 'may'\n",
    "        elif x == 'Mar': return 'march'\n",
    "        elif x == 'Apr': return 'april'\n",
    "        elif x == 'sept.': return 'september'\n",
    "        elif x == 'Feb': return 'february'\n",
    "        elif x == 'Oct': return 'october'\n",
    "        elif x == 'Nov': return 'november'\n",
    "        elif x == 'January': return 'january'\n",
    "        elif x == 'Dev': return 'december'\n",
    "\n",
    "month = pd.Series([cleanMonth(x) for x in X_combined.x19], name='month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Weekday Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cleanWeekday(x):\n",
    "    if isinstance(x, str):\n",
    "        if x == 'monday': return 'monday'\n",
    "        elif x == 'tuesday': return 'tuesday'\n",
    "        elif x == 'wednesday': return 'wednesday'\n",
    "        elif x == 'thurday': return 'thursday'\n",
    "        elif x == 'friday': return 'friday'\n",
    "\n",
    "weekday = pd.Series([cleanWeekday(x) for x in X_combined.x43], name='weekday')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Region Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cleanRegion(x):\n",
    "    if isinstance(x, str):\n",
    "        if x == 'asia': return 'asia'\n",
    "        elif x == 'euorpe': return 'europe'\n",
    "        elif x == 'america': return 'america'\n",
    "\n",
    "region = pd.Series([cleanRegion(x) for x in X_combined.x16], name='region')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Parse Money to Float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parseMoneyToFloat(x):\n",
    "    if isinstance(x, str): return float(re.sub('[$,()]', '', x))\n",
    "\n",
    "X_combined.x44 = [parseMoneyToFloat(x) for x in X_combined.x44]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Percent to Float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parsePercentToFloat(x):\n",
    "    if isinstance(x, str): return float(re.sub('%', '', x)) / 100.00\n",
    "\n",
    "X_combined.x09 = [parsePercentToFloat(x) for x in X_combined.x09]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Imputation  Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 51)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_combined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. **df0**: Numerical: Drop, Categorical: Drop\n",
    "2. **df1**: Numerical: Mean, Categorical: Frequency\n",
    "3. **df2**: Numerical: Median, Categorical: Frequency\n",
    "4. **df3**: k-Nearest Neighbors\n",
    "5. **df4**: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_numeric = X_combined.copy()\n",
    "X_numeric.drop(['x16', 'x19', 'x43'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df0 = X_numeric.copy()\n",
    "df1 = X_numeric.copy()\n",
    "df2 = X_numeric.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Missing Categorical Data with Most Frequent Value & Get Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "june    55795\n",
       "Name: month, dtype: int64"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month.value_counts()[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wednesday    126413\n",
       "Name: weekday, dtype: int64"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekday.value_counts()[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asia    173129\n",
       "Name: region, dtype: int64"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region.value_counts()[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "month.fillna('june', inplace=True)\n",
    "weekday.fillna('wednesday', inplace=True)\n",
    "region.fillna('asia', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df0: Numerical: Drop, Categorical: Drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df0['month'] = month.copy()\n",
    "#df0['weekday'] = weekday.copy()\n",
    "#df0['region'] = region.copy()\n",
    "#df0 = pd.get_dummies(df0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df0.dropna(inplace=True, subset=[col for col in df0.columns if col not in ['y']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df1: Numerical: Mean, Categorical: Most Frequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_df1 = df1.pop('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -5.90070664e+00,   4.69388657e-01,   4.73306785e+00, ...,\n",
       "          4.59280348e+00,  -3.44776760e-02,   3.68040134e+00],\n",
       "       [ -3.53039065e+00,   4.22981797e+00,  -4.61943288e+00, ...,\n",
       "         -5.46246671e+00,  -2.29517509e-01,  -2.33294711e+00],\n",
       "       [  1.00338855e+00,  -1.25474570e-02,   6.25050323e+00, ...,\n",
       "         -1.14070719e+01,   6.39555117e+00,   3.54533178e+00],\n",
       "       ..., \n",
       "       [  1.71043472e+01,   1.08815589e+01,   9.25710482e+00, ...,\n",
       "          6.07498027e+00,  -2.24617902e-01,   5.16245808e+00],\n",
       "       [  1.03181728e+01,  -8.79384077e+00,  -2.67099784e+00, ...,\n",
       "         -7.78997798e+00,   1.60228442e-01,  -2.71319396e+00],\n",
       "       [ -3.75580866e+00,   6.22956464e+00,  -1.28682043e+00, ...,\n",
       "          6.10818001e+01,   1.34704559e+00,  -7.67326474e-01]])"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanImputer = Imputer(strategy='mean', copy=False)\n",
    "meanImputer.fit_transform(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1['y'] = y_df1\n",
    "df1['month'] = month.copy()\n",
    "df1['weekday'] = weekday.copy()\n",
    "df1['region'] = region.copy()\n",
    "df1 = pd.get_dummies(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df2: Numerical: Median, Categorical: Most Frequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_df2 = df2.pop('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -5.90070664e+00,   4.69388657e-01,   4.73306785e+00, ...,\n",
       "          4.59280348e+00,  -3.44776760e-02,   3.68040134e+00],\n",
       "       [ -3.53039065e+00,   4.22981797e+00,  -4.61943288e+00, ...,\n",
       "         -5.46246671e+00,  -2.29517509e-01,  -2.33294711e+00],\n",
       "       [  1.00338855e+00,  -1.25474570e-02,   6.25050323e+00, ...,\n",
       "         -1.14070719e+01,   6.39555117e+00,   3.54533178e+00],\n",
       "       ..., \n",
       "       [  1.71043472e+01,   1.08815589e+01,   9.25710482e+00, ...,\n",
       "          6.07498027e+00,  -2.24617902e-01,   5.16245808e+00],\n",
       "       [  1.03181728e+01,  -8.79384077e+00,  -2.67099784e+00, ...,\n",
       "         -7.78997798e+00,   1.60228442e-01,  -2.71319396e+00],\n",
       "       [ -3.75580866e+00,   6.22956464e+00,  -1.28682043e+00, ...,\n",
       "          6.10818001e+01,   1.34704559e+00,  -7.67326474e-01]])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medianImputer = Imputer(strategy='median', copy=False)\n",
    "medianImputer.fit_transform(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2['y'] = y_df2\n",
    "df2['month'] = month.copy()\n",
    "df2['weekday'] = weekday.copy()\n",
    "df2['region'] = region.copy()\n",
    "df2 = pd.get_dummies(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Test/Train Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df1: Numerical: Mean, Categorical: Most Frequent\n",
    "\n",
    "# X TEST\n",
    "X_test_df1 = df1[np.isnan(df1.y)].copy()\n",
    "X_test_df1.drop('y', axis=1, inplace=True)\n",
    "\n",
    "# Xy TRAIN\n",
    "train_df1 = df1.dropna(subset=['y'])\n",
    "\n",
    "# y TRAIN\n",
    "y_train_df1 = train_df1['y'].copy()\n",
    "\n",
    "# X TRAIN\n",
    "X_train_df1 = train_df1.drop('y', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df2: Numerical: Median, Categorical: Most Frequent\n",
    "\n",
    "# X TEST\n",
    "X_test_df2 = df2[np.isnan(df2.y)].copy()\n",
    "X_test_df2.drop('y', axis=1, inplace=True)\n",
    "\n",
    "# Xy TRAIN\n",
    "train_df2 = df2.dropna(subset=['y'])\n",
    "\n",
    "# y TRAIN\n",
    "y_train_df2 = train_df2['y'].copy()\n",
    "\n",
    "# X TRAIN\n",
    "X_train_df2 = train_df2.drop('y', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Random Forest Classifer with K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getMeanAndConfidence(scores, name):\n",
    "    mean_score = scores.mean()\n",
    "    std_dev = scores.std()\n",
    "    std_error = scores.std() / math.sqrt(scores.shape[0])\n",
    "    ci =  2.262 * std_error\n",
    "    lower_bound = mean_score - ci\n",
    "    upper_bound = mean_score + ci\n",
    "    print (\"%s is %f +/-  %f\" % (name, mean_score, ci))\n",
    "    print ('95 percent probability that if this experiment were repeated over and over the average score would be between %f and %f' % (lower_bound, upper_bound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 is 0.869244 +/-  0.003206\n",
      "95 percent probability that if this experiment were repeated over and over the average score would be between 0.866037 and 0.872450\n"
     ]
    }
   ],
   "source": [
    "rfc_df1 = RandomForestClassifier(n_jobs=-1)\n",
    "df1_scores = cross_val_score(estimator=rfc_df1, X=X_train_df1, y=y_train_df1, cv=10, n_jobs=-1)\n",
    "getMeanAndConfidence(df1_scores, 'df1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df2 is 0.866537 +/-  0.002472\n",
      "95 percent probability that if this experiment were repeated over and over the average score would be between 0.864065 and 0.869010\n"
     ]
    }
   ],
   "source": [
    "rfc_df2 = RandomForestClassifier(n_jobs=-1)\n",
    "df2_scores = cross_val_score(estimator=rfc_df2, X=X_train_df2, y=y_train_df2, cv=10, n_jobs=-1)\n",
    "getMeanAndConfidence(df2_scores, 'df2')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
