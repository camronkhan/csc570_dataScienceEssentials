{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Retention Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import Imputer\n",
    "from scipy.stats import mode\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.options.display.max_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA = pd.read_csv(\"../../../kaggle_data/customer_retention/midterm_train.csv\")\n",
    "TEST_DATA = pd.read_csv(\"../../../kaggle_data/customer_retention/midterm_test.csv\")\n",
    "X = TRAIN_DATA\n",
    "X_combined = pd.concat([X, TEST_DATA])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 51)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_combined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Month Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cleanMonth(x):\n",
    "    if isinstance(x, str):\n",
    "        if x == 'Jun': return 'june'\n",
    "        elif x == 'July': return 'july'\n",
    "        elif x == 'Aug': return 'august'\n",
    "        elif x == 'May': return 'may'\n",
    "        elif x == 'Mar': return 'march'\n",
    "        elif x == 'Apr': return 'april'\n",
    "        elif x == 'sept.': return 'september'\n",
    "        elif x == 'Feb': return 'february'\n",
    "        elif x == 'Oct': return 'october'\n",
    "        elif x == 'Nov': return 'november'\n",
    "        elif x == 'January': return 'january'\n",
    "        elif x == 'Dev': return 'december'\n",
    "\n",
    "month = pd.Series([cleanMonth(x) for x in X_combined.x19], name='month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Weekday Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cleanWeekday(x):\n",
    "    if isinstance(x, str):\n",
    "        if x == 'monday': return 'monday'\n",
    "        elif x == 'tuesday': return 'tuesday'\n",
    "        elif x == 'wednesday': return 'wednesday'\n",
    "        elif x == 'thurday': return 'thursday'\n",
    "        elif x == 'friday': return 'friday'\n",
    "\n",
    "weekday = pd.Series([cleanWeekday(x) for x in X_combined.x43], name='weekday')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Region Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cleanRegion(x):\n",
    "    if isinstance(x, str):\n",
    "        if x == 'asia': return 'asia'\n",
    "        elif x == 'euorpe': return 'europe'\n",
    "        elif x == 'america': return 'america'\n",
    "\n",
    "region = pd.Series([cleanRegion(x) for x in X_combined.x16], name='region')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Parse Money to Float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parseMoneyToFloat(x):\n",
    "    if isinstance(x, str): return float(re.sub('[$,()]', '', x))\n",
    "\n",
    "X_combined.x44 = [parseMoneyToFloat(x) for x in X_combined.x44]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Percent to Float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parsePercentToFloat(x):\n",
    "    if isinstance(x, str): return float(re.sub('%', '', x)) / 100.00\n",
    "\n",
    "X_combined.x09 = [parsePercentToFloat(x) for x in X_combined.x09]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Imputation  Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 51)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_combined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. **df0**: Numerical: Drop, Categorical: Drop\n",
    "2. **df1**: Numerical: Mean, Categorical: Frequency\n",
    "3. **df2**: Numerical: Median, Categorical: Frequency\n",
    "4. **df3**: k-Nearest Neighbors\n",
    "5. **df4**: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_numeric = X_combined.copy()\n",
    "X_numeric.drop(['x16', 'x19', 'x43'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df0 = X_numeric.copy()\n",
    "df1 = X_numeric.copy()\n",
    "df2 = X_numeric.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Missing Categorical Data with Most Frequent Value & Get Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "june    55795\n",
       "Name: month, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month.value_counts()[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wednesday    126413\n",
       "Name: weekday, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekday.value_counts()[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asia    173129\n",
       "Name: region, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region.value_counts()[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "month.fillna('june', inplace=True)\n",
    "weekday.fillna('wednesday', inplace=True)\n",
    "region.fillna('asia', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df0: Numerical: Drop, Categorical: Drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df0['month'] = month.copy()\n",
    "#df0['weekday'] = weekday.copy()\n",
    "#df0['region'] = region.copy()\n",
    "#df0 = pd.get_dummies(df0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df0.dropna(inplace=True, subset=[col for col in df0.columns if col not in ['y']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df1: Numerical: Mean, Categorical: Most Frequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_df1 = df1.pop('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -5.90070664e+00,   4.69388657e-01,   4.73306785e+00, ...,\n",
       "          4.59280348e+00,  -3.44776760e-02,   3.68040134e+00],\n",
       "       [ -3.53039065e+00,   4.22981797e+00,  -4.61943288e+00, ...,\n",
       "         -5.46246671e+00,  -2.29517509e-01,  -2.33294711e+00],\n",
       "       [  1.00338855e+00,  -1.25474570e-02,   6.25050323e+00, ...,\n",
       "         -1.14070719e+01,   6.39555117e+00,   3.54533178e+00],\n",
       "       ..., \n",
       "       [  1.71043472e+01,   1.08815589e+01,   9.25710482e+00, ...,\n",
       "          6.07498027e+00,  -2.24617902e-01,   5.16245808e+00],\n",
       "       [  1.03181728e+01,  -8.79384077e+00,  -2.67099784e+00, ...,\n",
       "         -7.78997798e+00,   1.60228442e-01,  -2.71319396e+00],\n",
       "       [ -3.75580866e+00,   6.22956464e+00,  -1.28682043e+00, ...,\n",
       "          6.10818001e+01,   1.34704559e+00,  -7.67326474e-01]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanImputer = Imputer(strategy='mean', copy=False)\n",
    "meanImputer.fit_transform(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1['y'] = y_df1\n",
    "df1['month'] = month.copy()\n",
    "df1['weekday'] = weekday.copy()\n",
    "df1['region'] = region.copy()\n",
    "df1 = pd.get_dummies(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df2: Numerical: Median, Categorical: Most Frequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_df2 = df2.pop('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -5.90070664e+00,   4.69388657e-01,   4.73306785e+00, ...,\n",
       "          4.59280348e+00,  -3.44776760e-02,   3.68040134e+00],\n",
       "       [ -3.53039065e+00,   4.22981797e+00,  -4.61943288e+00, ...,\n",
       "         -5.46246671e+00,  -2.29517509e-01,  -2.33294711e+00],\n",
       "       [  1.00338855e+00,  -1.25474570e-02,   6.25050323e+00, ...,\n",
       "         -1.14070719e+01,   6.39555117e+00,   3.54533178e+00],\n",
       "       ..., \n",
       "       [  1.71043472e+01,   1.08815589e+01,   9.25710482e+00, ...,\n",
       "          6.07498027e+00,  -2.24617902e-01,   5.16245808e+00],\n",
       "       [  1.03181728e+01,  -8.79384077e+00,  -2.67099784e+00, ...,\n",
       "         -7.78997798e+00,   1.60228442e-01,  -2.71319396e+00],\n",
       "       [ -3.75580866e+00,   6.22956464e+00,  -1.28682043e+00, ...,\n",
       "          6.10818001e+01,   1.34704559e+00,  -7.67326474e-01]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medianImputer = Imputer(strategy='median', copy=False)\n",
    "medianImputer.fit_transform(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2['y'] = y_df2\n",
    "df2['month'] = month.copy()\n",
    "df2['weekday'] = weekday.copy()\n",
    "df2['region'] = region.copy()\n",
    "df2 = pd.get_dummies(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Test/Train Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df1: Numerical: Mean, Categorical: Most Frequent\n",
    "\n",
    "# X TEST\n",
    "X_test_df1 = df1[np.isnan(df1.y)].copy()\n",
    "X_test_df1.drop('y', axis=1, inplace=True)\n",
    "\n",
    "# Xy TRAIN\n",
    "train_df1 = df1.dropna(subset=['y'])\n",
    "\n",
    "# y TRAIN\n",
    "y_train_df1 = train_df1['y'].copy()\n",
    "\n",
    "# X TRAIN\n",
    "X_train_df1 = train_df1.drop('y', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df2: Numerical: Median, Categorical: Most Frequent\n",
    "\n",
    "# X TEST\n",
    "X_test_df2 = df2[np.isnan(df2.y)].copy()\n",
    "X_test_df2.drop('y', axis=1, inplace=True)\n",
    "\n",
    "# Xy TRAIN\n",
    "train_df2 = df2.dropna(subset=['y'])\n",
    "\n",
    "# y TRAIN\n",
    "y_train_df2 = train_df2['y'].copy()\n",
    "\n",
    "# X TRAIN\n",
    "X_train_df2 = train_df2.drop('y', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Random Forest Classifer with K-Fold Cross Validation and Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set hyperparameters\n",
    "n_estimators=[3, 5, 10, 15, 25, 40, 60, 100]\n",
    "criterion=['gini', 'entropy']\n",
    "max_features=['auto', 'log2', 0.8, None]\n",
    "min_samples_split=[2, 10, 100]\n",
    "min_samples_leaf=[1, 10, 100]\n",
    "min_weight_fraction_leaf=[0.0, 0.1, 0.2, 0.5]\n",
    "min_impurity_split=[1e-07, 1e-06, 1e-08]\n",
    "bootstrap=[True, False]\n",
    "oob_score=[False, True]\n",
    "\n",
    "hyperparameters = dict(n_estimators=n_estimators,criterion=criterion, max_features=max_features,\n",
    "                       min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf,\n",
    "                       min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "                       min_impurity_split=min_impurity_split, bootstrap=bootstrap, oob_score=oob_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get random forest classifier\n",
    "rfc = RandomForestClassifier(max_depth=None, max_leaf_nodes=None, n_jobs=-1, random_state=42,\n",
    "                             verbose=0, warm_start=False, class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit models to training sets\n",
    "\n",
    "#df1\n",
    "rfc_estimator_df1 = GridSearchCV(rfc, hyperparameters, scoring='roc_auc', n_jobs=-1, cv=cv)\n",
    "rfc_estimator_df1.fit(X_train_df1, y_train_df1)\n",
    "rfc_best_estimator_df1 = rfc_estimator_df1.best_estimator_\n",
    "print(rfc_best_estimator_df1)\n",
    "\n",
    "# df2\n",
    "rfc_estimator_df2 = GridSearchCV(rfc, hyperparameters, scoring='roc_auc', n_jobs=-1, cv=cv)\n",
    "rfc_estimator_df2.fit(X_train_df2, y_train_df2)\n",
    "rfc_best_estimator_df2 = rfc_estimator_df2.best_estimator_\n",
    "print(rfc_best_estimator_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getMeanAndConfidence(scores, scoring, name):\n",
    "    mean_score = scores.mean()\n",
    "    std_dev = scores.std()\n",
    "    std_error = scores.std() / math.sqrt(scores.shape[0])\n",
    "    ci =  2.262 * std_error\n",
    "    lower_bound = mean_score - ci\n",
    "    upper_bound = mean_score + ci\n",
    "    print (\"%s is %f +/-  %f\" % (name, mean_score, ci))\n",
    "    print ('95 percent probability that if this experiment were repeated over and over the average %s score would be between %f and %f' % (scoring, lower_bound, upper_bound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cross validation\n",
    "\n",
    "#df1\n",
    "roc_auc_df1 = cross_val_score(rfc_best_estimator_df1, X_train_df1, y_train_df1, cv=10, scoring='roc_auc')\n",
    "getMeanAndConfidence(roc_auc_df1, 'roc_auc', 'df1')\n",
    "\n",
    "#df2\n",
    "roc_auc_df2 = cross_val_score(rfc_best_estimator_df2, X_train_df2, y_train_df2, cv=10, scoring='roc_auc')\n",
    "getMeanAndConfidence(roc_auc_df2, 'roc_auc', 'df2')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
